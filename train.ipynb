{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78643b28",
   "metadata": {},
   "source": [
    "### here we use the ALL data set as an example, replace it with your own data set\n",
    "- update label variable with name of your own entity types\n",
    "- your own jsonl file should have one json string at each line\n",
    "- each json string represents a list of dictionary which must have 'text' and 'label' entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31487660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/data.jsonl') as f:\n",
    "    sents = [json.loads(line.strip()) for line in f]\n",
    "labels = ['Catalyst', 'Characterization', 'Product', 'Reactant', 'Reaction', 'Treatment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5150c710",
   "metadata": {},
   "source": [
    "### here we use the ALL data set as an example, replace it with your own data set\n",
    "- adjust `lr` and `epoch_number` first\n",
    "- then play with `neg_rate`\n",
    "- tune the rest parameter if you like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "wd = 0\n",
    "epoch_num = 40\n",
    "neg_rate = 1.4\n",
    "hidden = 256\n",
    "dropout = 0.1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7658a0",
   "metadata": {},
   "source": [
    "- checkpoing, output log, tensorboard(monitor loss) are stored under `checkpoint_dir`\n",
    "- `precision=16` enable half precision training which could accelerate training on newer Nvidia GPU(>Turing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad16907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T21:26:00.147285Z",
     "start_time": "2022-03-25T21:01:18.450253Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "epoch_num:40 total step: 13520 warmup step: 1352\n",
      "lr:5e-05 wd:0 batch:32\n",
      "\n",
      "  | Name            | Type     | Params\n",
      "---------------------------------------------\n",
      "0 | _encoder        | BERT     | 110 M \n",
      "1 | _span_criterion | Biaffine | 856 K \n",
      "---------------------------------------------\n",
      "111 M     Trainable params\n",
      "0         Non-trainable params\n",
      "111 M     Total params\n",
      "222.861   Total estimated model params size (MB)\n",
      "/data/zhangyue/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /data/zhangyue/cpi3/JCIM_Github/checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Global seed set to 12345\n",
      "Global seed set to 12345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1ba786fb9240bd921110a18bce88e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zhangyue/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.7102    0.8809    0.7864       512\n",
      "Characterization     0.5876    0.8261    0.6867        69\n",
      "         Product     0.8515    0.8864    0.8686       440\n",
      "        Reactant     0.8156    0.9126    0.8614       412\n",
      "        Reaction     0.7906    0.9205    0.8506       365\n",
      "       Treatment     0.6870    0.9091    0.7826       198\n",
      "\n",
      "       micro avg     0.7656    0.8968    0.8260      1996\n",
      "       macro avg     0.7404    0.8893    0.8061      1996\n",
      "    weighted avg     0.7713    0.8968    0.8279      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.7948   0.9312   0.8576      512\n",
      "Characterization       0.6460   0.9352   0.7642       69\n",
      "Product                0.8716   0.9193   0.8948      440\n",
      "Reactant               0.8587   0.9517   0.9028      412\n",
      "Reaction               0.8205   0.9616   0.8855      365\n",
      "Treatment              0.7107   0.9457   0.8115      198\n",
      "micro avg              0.8115   0.9399   0.8710     1996\n",
      "macro avg              0.7837   0.9408   0.8527     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.7550    0.8789    0.8123       512\n",
      "Characterization     0.6042    0.8406    0.7030        69\n",
      "         Product     0.8688    0.9182    0.8928       440\n",
      "        Reactant     0.8235    0.9175    0.8680       412\n",
      "        Reaction     0.8830    0.9507    0.9156       365\n",
      "       Treatment     0.7572    0.9293    0.8345       198\n",
      "\n",
      "       micro avg     0.8086    0.9123    0.8573      1996\n",
      "       macro avg     0.7820    0.9059    0.8377      1996\n",
      "    weighted avg     0.8126    0.9123    0.8588      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.8334   0.9184   0.8738      512\n",
      "Characterization       0.6580   0.9313   0.7712       69\n",
      "Product                0.8922   0.9460   0.9183      440\n",
      "Reactant               0.8639   0.9575   0.9083      412\n",
      "Reaction               0.8978   0.9662   0.9307      365\n",
      "Treatment              0.7807   0.9604   0.8613      198\n",
      "micro avg              0.8498   0.9459   0.8953     1996\n",
      "macro avg              0.8210   0.9466   0.8773     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.7684    0.8750    0.8183       512\n",
      "Characterization     0.6484    0.8551    0.7375        69\n",
      "         Product     0.8637    0.9364    0.8986       440\n",
      "        Reactant     0.8330    0.9199    0.8743       412\n",
      "        Reaction     0.8766    0.9534    0.9134       365\n",
      "       Treatment     0.7922    0.9242    0.8531       198\n",
      "\n",
      "       micro avg     0.8187    0.9163    0.8648      1996\n",
      "       macro avg     0.7970    0.9107    0.8492      1996\n",
      "    weighted avg     0.8207    0.9163    0.8656      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.8399   0.9328   0.8839      512\n",
      "Characterization       0.6969   0.9313   0.7972       69\n",
      "Product                0.8793   0.9518   0.9141      440\n",
      "Reactant               0.8688   0.9531   0.9090      412\n",
      "Reaction               0.8875   0.9680   0.9260      365\n",
      "Treatment              0.8126   0.9541   0.8777      198\n",
      "micro avg              0.8540   0.9497   0.8993     1996\n",
      "macro avg              0.8308   0.9485   0.8847     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.7807    0.8691    0.8226       512\n",
      "Characterization     0.6552    0.8261    0.7308        69\n",
      "         Product     0.8278    0.9068    0.8655       440\n",
      "        Reactant     0.8186    0.8981    0.8565       412\n",
      "        Reaction     0.8640    0.9397    0.9003       365\n",
      "       Treatment     0.7902    0.8939    0.8389       198\n",
      "\n",
      "       micro avg     0.8097    0.8973    0.8512      1996\n",
      "       macro avg     0.7894    0.8890    0.8357      1996\n",
      "    weighted avg     0.8107    0.8973    0.8517      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.8505   0.9190   0.8834      512\n",
      "Characterization       0.7031   0.9120   0.7940       69\n",
      "Product                0.8507   0.9435   0.8947      440\n",
      "Reactant               0.8572   0.9440   0.8985      412\n",
      "Reaction               0.8816   0.9575   0.9180      365\n",
      "Treatment              0.8156   0.9251   0.8669      198\n",
      "micro avg              0.8482   0.9370   0.8904     1996\n",
      "macro avg              0.8265   0.9335   0.8759     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8197    0.8613    0.8400       512\n",
      "Characterization     0.7692    0.8696    0.8163        69\n",
      "         Product     0.8779    0.9318    0.9041       440\n",
      "        Reactant     0.8710    0.9175    0.8936       412\n",
      "        Reaction     0.8892    0.9452    0.9163       365\n",
      "       Treatment     0.8211    0.9040    0.8606       198\n",
      "\n",
      "       micro avg     0.8540    0.9083    0.8803      1996\n",
      "       macro avg     0.8414    0.9049    0.8718      1996\n",
      "    weighted avg     0.8542    0.9083    0.8804      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.8873   0.8967   0.8920      512\n",
      "Characterization       0.8034   0.9120   0.8543       69\n",
      "Product                0.8942   0.9398   0.9165      440\n",
      "Reactant               0.9050   0.9513   0.9276      412\n",
      "Reaction               0.9068   0.9598   0.9325      365\n",
      "Treatment              0.8438   0.9366   0.8878      198\n",
      "micro avg              0.8885   0.9335   0.9104     1996\n",
      "macro avg              0.8734   0.9327   0.9018     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8080    0.8633    0.8347       512\n",
      "Characterization     0.7403    0.8261    0.7808        69\n",
      "         Product     0.8545    0.9341    0.8925       440\n",
      "        Reactant     0.8886    0.9102    0.8993       412\n",
      "        Reaction     0.8956    0.9397    0.9171       365\n",
      "       Treatment     0.8203    0.8990    0.8578       198\n",
      "\n",
      "       micro avg     0.8491    0.9048    0.8761      1996\n",
      "       macro avg     0.8345    0.8954    0.8637      1996\n",
      "    weighted avg     0.8498    0.9048    0.8763      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.8904   0.9039   0.8971      512\n",
      "Characterization       0.7944   0.9120   0.8491       69\n",
      "Product                0.8775   0.9532   0.9138      440\n",
      "Reactant               0.9232   0.9416   0.9323      412\n",
      "Reaction               0.9121   0.9521   0.9316      365\n",
      "Treatment              0.8431   0.9339   0.8862      198\n",
      "micro avg              0.8896   0.9346   0.9115     1996\n",
      "macro avg              0.8734   0.9328   0.9017     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8311    0.8359    0.8335       512\n",
      "Characterization     0.7568    0.8116    0.7832        69\n",
      "         Product     0.8487    0.9182    0.8821       440\n",
      "        Reactant     0.8767    0.9150    0.8955       412\n",
      "        Reaction     0.9129    0.9479    0.9301       365\n",
      "       Treatment     0.8333    0.8838    0.8578       198\n",
      "\n",
      "       micro avg     0.8570    0.8948    0.8755      1996\n",
      "       macro avg     0.8433    0.8854    0.8637      1996\n",
      "    weighted avg     0.8570    0.8948    0.8753      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9042   0.8766   0.8902      512\n",
      "Characterization       0.8131   0.8975   0.8532       69\n",
      "Product                0.8715   0.9384   0.9037      440\n",
      "Reactant               0.9114   0.9464   0.9286      412\n",
      "Reaction               0.9244   0.9571   0.9404      365\n",
      "Treatment              0.8557   0.9137   0.8838      198\n",
      "micro avg              0.8937   0.9238   0.9085     1996\n",
      "macro avg              0.8800   0.9216   0.9000     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8413    0.8281    0.8346       512\n",
      "Characterization     0.7671    0.8116    0.7887        69\n",
      "         Product     0.8614    0.9182    0.8889       440\n",
      "        Reactant     0.8842    0.9078    0.8958       412\n",
      "        Reaction     0.9241    0.9342    0.9292       365\n",
      "       Treatment     0.8294    0.8838    0.8557       198\n",
      "\n",
      "       micro avg     0.8658    0.8888    0.8771      1996\n",
      "       macro avg     0.8512    0.8806    0.8655      1996\n",
      "    weighted avg     0.8660    0.8888    0.8770      1996\n",
      "\n",
      "\n",
      "\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9150   0.8705   0.8922      512\n",
      "Characterization       0.8139   0.8830   0.8471       69\n",
      "Product                0.8802   0.9356   0.9071      440\n",
      "Reactant               0.9193   0.9392   0.9291      412\n",
      "Reaction               0.9313   0.9388   0.9351      365\n",
      "Treatment              0.8517   0.9137   0.8816      198\n",
      "micro avg              0.9008   0.9162   0.9084     1996\n",
      "macro avg              0.8853   0.9135   0.8987     1996\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from copy import deepcopy\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "bert_name = 'pretrained/scibert_domain_adaption'\n",
    "checkpoint_dir = 'checkpoint'\n",
    "checkpoint_name = 'train_demo'\n",
    "\n",
    "root = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "root.addHandler(logging.FileHandler(f'{checkpoint_dir}/{checkpoint_name}.log'))\n",
    "callbacks = [pl.callbacks.ModelCheckpoint(dirpath=checkpoint_dir, filename=f'{checkpoint_name}_checkpoint')]\n",
    "logger = [pl.loggers.TensorBoardLogger(checkpoint_dir, name=f'{checkpoint_name}_tfboard')]\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    enable_checkpointing=True,\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    num_sanity_val_steps=0,\n",
    "    check_val_every_n_epoch=5,\n",
    "    gradient_clip_val=5,\n",
    "    max_epochs=epoch_num,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# here demostrate the train process using the last 1000 sentence as validation data set and the rest as training data set\n",
    "model = BERTSpan(bert_name, sents[:-1000], sents[-1000:], [], labels, batch_size,\n",
    "                 neg_rate, hidden, dropout, lr, wd, epoch_num)        \n",
    "\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e40bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
