{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4cf60ea",
   "metadata": {},
   "source": [
    "### load the ALL data set and split it into 5 cross validation fold with correspond ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69145360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/data.jsonl') as f:\n",
    "    sents = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "with open('data/split.jsonl') as f:\n",
    "    cv_data = []\n",
    "    for line in f:\n",
    "        ids = json.loads(line.strip())\n",
    "        train_ids, test_ids = ids['train_ids'], ids['test_ids']\n",
    "        train_data = [sents[idx] for idx in train_ids]\n",
    "        test_data = [sents[idx]  for idx in test_ids]\n",
    "        cv_data.append((train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd562bd",
   "metadata": {},
   "source": [
    "### load model checkpoint for each fold and test it on corresponding validation set\n",
    "- `model.test_report` stores test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad16907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T18:52:35.033659Z",
     "start_time": "2022-03-25T18:51:16.098449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 12345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b6bf3f33af4a30873cf8e34c3c2ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zhangyue/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:root:#### Strict Match Report ####\n",
      "INFO:root:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8589    0.8804    0.8695      1279\n",
      "Characterization     0.7662    0.8324    0.7979       185\n",
      "         Product     0.8949    0.9183    0.9065      1224\n",
      "        Reactant     0.9248    0.9132    0.9189      1198\n",
      "        Reaction     0.9338    0.9417    0.9377       943\n",
      "       Treatment     0.7995    0.8505    0.8242       408\n",
      "\n",
      "       micro avg     0.8870    0.9038    0.8953      5237\n",
      "       macro avg     0.8630    0.8894    0.8758      5237\n",
      "    weighted avg     0.8880    0.9038    0.8957      5237\n",
      "\n",
      "\n",
      "INFO:root:#### Soft Match Report ####\n",
      "INFO:root:\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9103   0.9249   0.9176     1279\n",
      "Characterization       0.8275   0.8891   0.8572      185\n",
      "Product                0.9224   0.9418   0.9320     1224\n",
      "Reactant               0.9525   0.9398   0.9461     1198\n",
      "Reaction               0.9507   0.9577   0.9542      943\n",
      "Treatment              0.8321   0.8924   0.8612      408\n",
      "micro avg              0.9202   0.9344   0.9272     5237\n",
      "macro avg              0.8992   0.9243   0.9114     5237\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'micro_f1': 0.8952993750572205}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 12345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4db77cf4304ba9a5b21d908b4da45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:#### Strict Match Report ####\n",
      "INFO:root:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8537    0.8774    0.8654      1264\n",
      "Characterization     0.8140    0.8750    0.8434       200\n",
      "         Product     0.8729    0.9094    0.8908      1148\n",
      "        Reactant     0.8915    0.8998    0.8956      1068\n",
      "        Reaction     0.9112    0.9247    0.9179       877\n",
      "       Treatment     0.8017    0.8942    0.8455       416\n",
      "\n",
      "       micro avg     0.8697    0.8993    0.8842      4973\n",
      "       macro avg     0.8575    0.8968    0.8764      4973\n",
      "    weighted avg     0.8705    0.8993    0.8845      4973\n",
      "\n",
      "\n",
      "INFO:root:#### Soft Match Report ####\n",
      "INFO:root:\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9064   0.9212   0.9137     1264\n",
      "Characterization       0.8438   0.9107   0.8760      200\n",
      "Product                0.9137   0.9500   0.9315     1148\n",
      "Reactant               0.9317   0.9367   0.9342     1068\n",
      "Reaction               0.9276   0.9481   0.9378      877\n",
      "Treatment              0.8195   0.9145   0.8644      416\n",
      "micro avg              0.9066   0.9350   0.9206     4973\n",
      "macro avg              0.8904   0.9302   0.9096     4973\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'micro_f1': 0.8842313289642334}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 12345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7131316ff8db4f76b162edd12a28d151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:#### Strict Match Report ####\n",
      "INFO:root:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8569    0.8645    0.8607      1240\n",
      "Characterization     0.8112    0.8670    0.8381       218\n",
      "         Product     0.8942    0.9237    0.9087      1180\n",
      "        Reactant     0.9093    0.9055    0.9074      1185\n",
      "        Reaction     0.9200    0.9329    0.9264       850\n",
      "       Treatment     0.8195    0.8860    0.8514       456\n",
      "\n",
      "       micro avg     0.8822    0.9010    0.8915      5129\n",
      "       macro avg     0.8685    0.8966    0.8821      5129\n",
      "    weighted avg     0.8828    0.9010    0.8916      5129\n",
      "\n",
      "\n",
      "INFO:root:#### Soft Match Report ####\n",
      "INFO:root:\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9133   0.9047   0.9090     1240\n",
      "Characterization       0.8511   0.9128   0.8809      218\n",
      "Product                0.9227   0.9441   0.9333     1180\n",
      "Reactant               0.9395   0.9390   0.9393     1185\n",
      "Reaction               0.9358   0.9516   0.9436      850\n",
      "Treatment              0.8359   0.8965   0.8651      456\n",
      "micro avg              0.9150   0.9291   0.9220     5129\n",
      "macro avg              0.8997   0.9248   0.9119     5129\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'micro_f1': 0.8914825916290283}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 12345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f448f5a84604c719d916149619cd08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:#### Strict Match Report ####\n",
      "INFO:root:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8602    0.8478    0.8539      1393\n",
      "Characterization     0.7796    0.8056    0.7923       180\n",
      "         Product     0.8929    0.9023    0.8975      1136\n",
      "        Reactant     0.8915    0.9019    0.8967      1121\n",
      "        Reaction     0.9101    0.9189    0.9145       925\n",
      "       Treatment     0.8076    0.8662    0.8359       441\n",
      "\n",
      "       micro avg     0.8754    0.8841    0.8797      5196\n",
      "       macro avg     0.8570    0.8738    0.8651      5196\n",
      "    weighted avg     0.8757    0.8841    0.8798      5196\n",
      "\n",
      "\n",
      "INFO:root:#### Soft Match Report ####\n",
      "INFO:root:\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9194   0.9019   0.9106     1393\n",
      "Characterization       0.8116   0.8579   0.8341      180\n",
      "Product                0.9309   0.9320   0.9315     1136\n",
      "Reactant               0.9285   0.9442   0.9362     1121\n",
      "Reaction               0.9281   0.9377   0.9329      925\n",
      "Treatment              0.8289   0.9004   0.8632      441\n",
      "micro avg              0.9135   0.9223   0.9179     5196\n",
      "macro avg              0.8912   0.9124   0.9014     5196\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'micro_f1': 0.8797395825386047}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 12345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c66f68eff6e4d7c8cef37fa6409eba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:#### Strict Match Report ####\n",
      "INFO:root:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Catalyst     0.8618    0.8677    0.8648      1179\n",
      "Characterization     0.8678    0.8728    0.8703       173\n",
      "         Product     0.8763    0.9041    0.8900      1168\n",
      "        Reactant     0.9091    0.9059    0.9075      1126\n",
      "        Reaction     0.8991    0.9238    0.9113       945\n",
      "       Treatment     0.7945    0.8810    0.8356       496\n",
      "\n",
      "       micro avg     0.8754    0.8964    0.8858      5087\n",
      "       macro avg     0.8681    0.8926    0.8799      5087\n",
      "    weighted avg     0.8762    0.8964    0.8860      5087\n",
      "\n",
      "\n",
      "INFO:root:#### Soft Match Report ####\n",
      "INFO:root:\n",
      "                    precision   recall f1-score  support\n",
      "Catalyst               0.9150   0.9194   0.9172     1179\n",
      "Characterization       0.9090   0.8996   0.9043      173\n",
      "Product                0.9072   0.9324   0.9196     1168\n",
      "Reactant               0.9396   0.9338   0.9367     1126\n",
      "Reaction               0.9174   0.9539   0.9353      945\n",
      "Treatment              0.8167   0.9103   0.8610      496\n",
      "micro avg              0.9084   0.9304   0.9192     5087\n",
      "macro avg              0.9008   0.9249   0.9123     5087\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'micro_f1': 0.8857808709144592}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from copy import deepcopy\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=False,\n",
    "    gpus=1\n",
    ")\n",
    "\n",
    "report = []\n",
    "for i in range(5):\n",
    "    ckpt_name = f'checkpoint/CV_{i}.ckpt'\n",
    "    bert_name = 'pretrained/scibert_domain_adaption'\n",
    "    train_data, val_data = cv_data[i]\n",
    "    model = BERTSpan.load_from_checkpoint(ckpt_name, model_name=bert_name, train_dataset=[], val_dataset=[], test_dataset=val_data)\n",
    "    trainer.test(model)\n",
    "    report.append(deepcopy(model.test_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb08fba",
   "metadata": {},
   "source": [
    "### group 5 fold result together\n",
    "- the mean column is what we report in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9fb54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T19:37:47.581206Z",
     "start_time": "2022-03-25T19:37:47.542320Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Strict Match Report ####################\n",
      "                                 fold 1       fold 2       fold 3       fold 4       fold 5         mean\n",
      "label            metric                                                                                 \n",
      "Catalyst         precision     0.858886     0.853734     0.856914     0.860160     0.861837     0.858306\n",
      "                 recall        0.880375     0.877373     0.864516     0.847810     0.867684     0.867552\n",
      "                 f1-score      0.869498     0.865392     0.860699     0.853941     0.864751     0.862856\n",
      "                 support    1279.000000  1264.000000  1240.000000  1393.000000  1179.000000  1271.000000\n",
      "Characterization precision     0.766169     0.813953     0.811159     0.779570     0.867816     0.807733\n",
      "                 recall        0.832432     0.875000     0.866972     0.805556     0.872832     0.850559\n",
      "                 f1-score      0.797927     0.843373     0.838137     0.792350     0.870317     0.828421\n",
      "                 support     185.000000   200.000000   218.000000   180.000000   173.000000   191.200000\n",
      "Product          precision     0.894904     0.872910     0.894176     0.892857     0.876349     0.886239\n",
      "                 recall        0.918301     0.909408     0.923729     0.902289     0.904110     0.911567\n",
      "                 f1-score      0.906452     0.890785     0.908712     0.897548     0.890013     0.898702\n",
      "                 support    1224.000000  1148.000000  1180.000000  1136.000000  1168.000000  1171.200000\n",
      "Reactant         precision     0.924768     0.891466     0.909322     0.891534     0.909091     0.905236\n",
      "                 recall        0.913189     0.899813     0.905485     0.901873     0.905861     0.905244\n",
      "                 f1-score      0.918942     0.895620     0.907400     0.896674     0.907473     0.905222\n",
      "                 support    1198.000000  1068.000000  1185.000000  1121.000000  1126.000000  1139.600000\n",
      "Reaction         precision     0.933754     0.911236     0.919954     0.910064     0.899073     0.914816\n",
      "                 recall        0.941676     0.924743     0.932941     0.918919     0.923810     0.928418\n",
      "                 f1-score      0.937698     0.917940     0.926402     0.914470     0.911273     0.921557\n",
      "                 support     943.000000   877.000000   850.000000   925.000000   945.000000   908.000000\n",
      "Treatment        precision     0.799539     0.801724     0.819473     0.807611     0.794545     0.804578\n",
      "                 recall        0.850490     0.894231     0.885965     0.866213     0.881048     0.875589\n",
      "                 f1-score      0.824228     0.845455     0.851423     0.835886     0.835564     0.838511\n",
      "                 support     408.000000   416.000000   456.000000   441.000000   496.000000   443.400000\n",
      "micro avg        precision     0.886994     0.869701     0.882207     0.875381     0.875408     0.877938\n",
      "                 recall        0.903762     0.899256     0.900955     0.884142     0.896403     0.896903\n",
      "                 f1-score      0.895299     0.884231     0.891483     0.879740     0.885781     0.887307\n",
      "                 support    5237.000000  4973.000000  5129.000000  5196.000000  5087.000000  5124.400000\n",
      "macro avg        precision     0.863003     0.857504     0.868500     0.856966     0.868118     0.862818\n",
      "                 recall        0.889410     0.896761     0.896601     0.873777     0.892558     0.889822\n",
      "                 f1-score      0.875791     0.876427     0.882129     0.865145     0.879899     0.875878\n",
      "                 support    5237.000000  4973.000000  5129.000000  5196.000000  5087.000000  5124.400000\n",
      "\n",
      "\n",
      "\n",
      "#################### Soft Match Report ####################\n",
      "                                 fold 1       fold 2       fold 3       fold 4       fold 5         mean\n",
      "label            metric                                                                                 \n",
      "Catalyst         precision     0.910344     0.906354     0.913292     0.919433     0.915017     0.912888\n",
      "                 recall        0.924884     0.921204     0.904711     0.901922     0.919387     0.914422\n",
      "                 f1-score      0.917557     0.913718     0.908981     0.910593     0.917197     0.913609\n",
      "                 support    1279.000000  1264.000000  1240.000000  1393.000000  1179.000000  1271.000000\n",
      "Characterization precision     0.827529     0.843798     0.851141     0.811572     0.909004     0.848609\n",
      "                 recall        0.889060     0.910667     0.912844     0.857937     0.899566     0.894015\n",
      "                 f1-score      0.857192     0.875958     0.880913     0.834110     0.904261     0.870487\n",
      "                 support     185.000000   200.000000   218.000000   180.000000   173.000000   191.200000\n",
      "Product          precision     0.922399     0.913683     0.922655     0.930938     0.907169     0.919369\n",
      "                 recall        0.941813     0.950026     0.944117     0.931988     0.932409     0.940071\n",
      "                 f1-score      0.932005     0.931500     0.933263     0.931463     0.919616     0.929569\n",
      "                 support    1224.000000  1148.000000  1180.000000  1136.000000  1168.000000  1171.200000\n",
      "Reactant         precision     0.952463     0.931683     0.939506     0.928474     0.939602     0.938345\n",
      "                 recall        0.939758     0.936727     0.939001     0.944152     0.933763     0.938680\n",
      "                 f1-score      0.946067     0.934198     0.939253     0.936248     0.936673     0.938488\n",
      "                 support    1198.000000  1068.000000  1185.000000  1121.000000  1126.000000  1139.600000\n",
      "Reaction         precision     0.950666     0.927634     0.935808     0.928074     0.917355     0.931908\n",
      "                 recall        0.957736     0.948148     0.951569     0.937730     0.953880     0.949813\n",
      "                 f1-score      0.954188     0.937779     0.943623     0.932877     0.935261     0.940746\n",
      "                 support     943.000000   877.000000   850.000000   925.000000   945.000000   908.000000\n",
      "Treatment        precision     0.832066     0.819504     0.835869     0.828929     0.816727     0.826619\n",
      "                 recall        0.892361     0.914463     0.896455     0.900389     0.910282     0.902790\n",
      "                 f1-score      0.861159     0.864384     0.865102     0.863182     0.860971     0.862960\n",
      "                 support     408.000000   416.000000   456.000000   441.000000   496.000000   443.400000\n",
      "micro avg        precision     0.920220     0.906599     0.915030     0.913461     0.908354     0.912733\n",
      "                 recall        0.934359     0.934955     0.929076     0.922327     0.930405     0.930225\n",
      "                 f1-score      0.927235     0.920559     0.922000     0.917873     0.919247     0.921383\n",
      "                 support    5237.000000  4973.000000  5129.000000  5196.000000  5087.000000  5124.400000\n",
      "macro avg        precision     0.899245     0.890443     0.899712     0.891237     0.900812     0.896290\n",
      "                 recall        0.924269     0.930206     0.924783     0.912353     0.924881     0.923298\n",
      "                 f1-score      0.911361     0.909590     0.911856     0.901412     0.912330     0.909310\n",
      "                 support    5237.000000  4973.000000  5129.000000  5196.000000  5087.000000  5124.400000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def report_summary(report_list):\n",
    "    metric_name = ['precision', 'recall', 'f1-score', 'support']\n",
    "    outer_index = []\n",
    "    inner_index = []\n",
    "    val_mat = []\n",
    "    for label in ['Catalyst', 'Characterization', 'Product', 'Reactant', 'Reaction', 'Treatment'] + ['micro avg', 'macro avg']:\n",
    "        for name in metric_name:\n",
    "            val_list = []\n",
    "            for val_res in report_list:\n",
    "                if label not in val_res:\n",
    "                    val_list.append(0)\n",
    "                else:\n",
    "                    val_list.append(val_res[label][name])\n",
    "            val_list.append(np.mean(val_list))\n",
    "            val_mat.append(val_list)\n",
    "            outer_index.append(label)\n",
    "            inner_index.append(name)\n",
    "    df_index = pd.MultiIndex.from_arrays([outer_index, inner_index], names=['label', 'metric'])\n",
    "    df = pd.DataFrame(val_mat, columns=[f'fold {i + 1}' for i in range(len(report_list))] + ['mean'], index=df_index)\n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print(df)\n",
    "\n",
    "#summerize 5 fold result     \n",
    "print('#'*20 +' Strict Match Report '+'#'*20)\n",
    "report_summary([r[-1][0] for r in report])\n",
    "print('\\n\\n')\n",
    "print('#'*20 +' Soft Match Report '+'#'*20)\n",
    "report_summary([r[-1][1] for r in report])\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e40bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
